{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Voice Commander\n",
    "Jan Jasiński (lider, numer albumu: 285390), \n",
    "Jan Wilczek (numer albumu: 285433)\n",
    "\n",
    "Link do repozytorium: https://github.com/Jasinsk/VoiceCommander\n",
    "\n",
    "***\n",
    "## Raport 1 (21.12.17-04.01.18)\n",
    "\n",
    "1. Cel projektu\n",
    "\n",
    "  Celem projektu jest stworzenie systemu wspomagającego produktywność (oraz wygodę) interakcji z komputerem poprzez wykorzystanie komend głosowych. Dodatkowo system taki użyty może zostać przez osoby starsze lub niepełnosprawne aby usprawnić obsługę komputera.\n",
    " \n",
    "3. Proponowana architektura projektu\n",
    "   1. Main - Łączy działanie wszystkich klas.\n",
    "   2. NameListener - Nasłuchuje na pojawienia się klucza aktywacyjnego.\n",
    "   3. Recorder - Nagrywa komendę i wysyła ją do rozpoznania. Zwraca otrzymane wyniki.\n",
    "   4. CommandRecognizer - Przyjmuje wyniki z rozpoznania i patrzy czy coś z tego mogło byc komenda i z jakim prawdopodobieństwem. Zwraca komendę, która należy wywołać lub informację o braku rozpoznania.\n",
    "   5. CommandHandler - Przyjmuje komendę, którą nalezy wykonać i wykonuje przypisane do niej czynności.\n",
    "   6. TTS - Łączy się z jakimś zewnętrznym ttsem, mówi mu co ma powiedzieć i pozwala na odtworzenie wyniku.\n",
    "   7. TTSHandler - Obsługuje co i w jakich momentach ma byc mówione przez system.\n",
    "\n",
    "   <b>Powyższa architektura nie jest sztywną wytyczną w naszych działaniach</b> - planujemy najpierw stworzyć działający prototyp, który będzie w stanie rozpoznać jedną komendę w trzech wariacjach i na jego podstawie otrzymać szkielet projektu, na którym bazowalibyśmy w dalszych pracach.\n",
    "\n",
    "4. Kwestie związane z obsługą systemu\n",
    "     1. Język obsługi systemu - polski.\n",
    "\n",
    "     2. Imię systemu\n",
    "  Powinno ono być zwięzłe i wygodne do wymawiania, charakterystyczne z punktu widzenia językowego, żeby nie było mylone z komendami, przyjazne dla użytkownika (pewne niedociągnięcia systemów są łagodniej traktowane w momencie, kiedy system ma jakąś osobowość) i zawierające się w słowniku systemu rozpoznawania mowy, którego będziemy uzywać.\n",
    "\n",
    "     3. Aktywacja systemu\n",
    "  We wstępnej wersji programu będziemy podawać komendę przy włączeniu programu, żeby zobaczyć czy cały system działa. Docelowo trzeba wymyślić wygodne i sprawne rozwiązanie tego problemu.\n",
    "  Wykorzystanie skrótu klawiszowego trochę niweczy cały sens systemu, bo skoro i tak trzeba naciskać klawize to o wiele łatwiej i sprawniej jest zaprogramować własne skróty klawiszowe. \n",
    "  Aktywacja głosowa systemu wydaje się najsprawniejszym obecnie rozwiązaniem, jednak jako, iż jest to standardowe wyjście dla wszystkich wirtualnych asystentów sterowanych mową warto byłoby sie zastanowić czy nie wymyslimy czegoś innego co działałoby sprawniej dla naszego systemu.\n",
    "\n",
    "5. Lista przewidywanych komend\n",
    "   1. Otwórz program X\n",
    "   2. Rozpocznij dyktowanie\n",
    "   3. Zakończ dyktowanie\n",
    "   4. Wyżej (scroll up)\n",
    "   5. Niżej (scroll down)\n",
    "   6. Góra (home)\n",
    "   7. Rzuć X na lewo/prawo (screen split)\n",
    "   8. Kopiuj\n",
    "   9. Wklej\n",
    "   10. Zapisz\n",
    "   11. Cofnij\n",
    "   12. Otwórz stronę X (w nowej karcie)\n",
    "   13. Zgoogluj \"coś\"\n",
    "\n",
    "6. Przewidywane problemy\n",
    "   1. Czas reakcji systemu - nagrywanie, łączenie się z serwerem, wysyłanie pliku audio, czekanie na wynik, rozpatrywanie czy coś jest komendą, wykonywanie komendy, wysyłanie tekstu do tts, otrzymywanie pliku audio, odtworzenie go - wszystkie te czynności będą zajmowały znaczącą ilosć czasu. Czas reakcji systemu nie może wynosić więcej niż kilka sekund jeżeli ma on działać sprawnie. \n",
    "\n",
    "   2. Text-to-speech - Byłoby to bardzo dobre rozwiązanie, jednak ciężko powiedzieć czy jego implementacja nie spowolni dodatkowo systemu. Możliwe, że dla tak ograniczonego systemu bardziej korzystne będzie nagranie wszystkich odpowiedzi i odgrywanie ich z plików.\n",
    "\n",
    "   3. Źródło audio - Konieczne będzie rozpoznanie jak jakość nagrywanego i wysyłanego audio wpływa na skuteczność i czas reakcji systemu rozpoznania mowy.\n",
    "\n",
    "   4. Aktywacja systemu\n",
    "  Jeżeli wykorzystana zostanie aktywacja głosowa systemu przy pomocy komendy startowej to trzeba rozplanować jak to zrobić aby jednocześnie działało to sprawnie, ale również nie wykorzystywało zbyt duzej ilości zasobów komputera podczas nasłuchiwania. Ciagłe nagrywanie audio, wysyłanie je na serwer i oczekiwanie na odpowiedź wydaje się bardzo nieoptymalnym rozwiązaniem. Pierwszym krokiem jaki trzeba wykonać to stworzenie bramki, która uruchamiać będzie analizę nagrywanego materiału. Najprostszym rozwiązaniem jest analiza natężenia dźwięku i analizowanie sygnału dopiero po wyraźnym jego skoku. \n",
    "  Zastanawiamy się nad wykorzystaniem systemu, który stworzyliśmy przy okazji miniprojektu, w celu usprawnienia rozpoznawania komendy aktywizacyjnej. Stworzenie wewnątrz systemu programu, który wytrenowany byłby do rozpoznawania komendy startowej zwolniłoby nas od potrzeby wysyłanie danych do serweru przy każdej sytuacji. Dopiero po zatwierdzniu hasła startowego system zaczynałby wysyłanie nagrywanego audio w celu rozpoznania mowy.\n",
    " \n",
    "1. Wykorzystywane systemy z uzasadnieniem\n",
    "    W naszym projekcie użyjemy głównie systemu Sarmata do rozpoznawania mowy z zadaną gramatyką, gdyż nasz system będzie rozpoznawał konkretne komendy, które użytkownik powinien znać, aby poprawnie korzystać z systemu. Dodatkowo planujemy użycie serwisu Dictation do dyktowania tekstu (na przykład do pliku tekstowego) oraz zastanawiamy się nad użyciem serwisu Trybun do syntezy mowy, aby przedstawiać komunikaty systemu także w postaci mowy.\n",
    "    \n",
    "1. Plan pracy\n",
    "    Jest to ramowy plan, który będzie uszczegóławiany w czasie trwania projektu. W kolejnym etapie prac zadania dotyczące klienta Sarmaty i gramatyki prototypu wykonywał będzie Jan Jasiński, a kod obsługujący nasłuchiwanie i wykonywanie komend napisze Jan Wilczek.\n",
    "    \n",
    "<img src=\"Gantt_chart.png\">\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
